<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>K8s in Action Notes</title>
      <link href="2021/03/06/K8s-in-Action-Note/"/>
      <url>2021/03/06/K8s-in-Action-Note/</url>
      
        <content type="html"><![CDATA[<p>这里是 <em>Kubernetes in Action</em> 的读书笔记。</p><h3 id="Chapter-1-介绍K8s"><a href="#Chapter-1-介绍K8s" class="headerlink" title="Chapter 1 介绍K8s"></a>Chapter 1 介绍K8s</h3><p>为什么需要K8s?  </p><ul><li>因为由单体式程序(monolithic)转向微服务式程序，因此需用像K8s这种工具帮助开发者和运维团队。  </li><li>微服务通过水平扩容来提高请求处理能力，要求能运维上能迅速扩容/缩容。</li><li>不同的微服务依赖于不同版本的库甚至环境，对于这些资源的隔离需用docker以及K8s这类工具。</li><li>K8s能实现运维的自动化，docker减小了开发，测试和线上环境的差异，为应用提供一个更稳定的环境。</li><li>…</li></ul><p>Docker通过Unix/Linux的命名空间(namespace)实现比VM更轻量的资源隔离。Docker的主要概念包括下面三个。</p><ul><li>images: 将应用和环境打包的产物</li><li>registries: 存储Docker image的仓库</li><li>containers: 通过Docker image创建的Linux容器</li></ul><p>Docker images是由多层(layers)组成的，不同的images可以包含相同的层。image的层是只读的，因此共享同一层的不同容器可以看到相同的文件系统，但是不能看到对方的修改。修改会作为一个新层加上去。</p><h4 id="K8s的结构"><a href="#K8s的结构" class="headerlink" title="K8s的结构"></a>K8s的结构</h4><p>K8s由master和worker node(s)组成。Master上运行着control plane，控制和管理整个K8s系统，worker nodes真正运行部署的应用。<br>Control Plane</p><ul><li>Kubernetes API Server: 用户和control plane其他组件交互的工具。</li><li>Scheduler: 为需要部署的应用调度worker nodes。</li><li>Controller Manager: 执行集群级别的工作，例如复制组件，追踪worker nodes，处理节点失败等情况。</li><li>etcd: 一个强一致配置中心。</li></ul><p>Nodes</p><ul><li>container runtime: docker, rkt等运行容器的。</li><li>Kubelet: 和API Server交互，管理本node上的容器。</li><li>kube-proxy: 负责管理应用之间的网络。</li></ul><p>用户通过声明需要部署什么应用，各需要多少各replica，每个应用的image应该如何获取。K8s会自己决定应该把各个应用实例调度到那个node上。<br><img src="k8s_fig1.png" alt="K8s的基本运作方式"></p><h3 id="Chapter-2-开始使用K8s和Docker"><a href="#Chapter-2-开始使用K8s和Docker" class="headerlink" title="Chapter 2 开始使用K8s和Docker"></a>Chapter 2 开始使用K8s和Docker</h3><h4 id="简单使用Docker"><a href="#简单使用Docker" class="headerlink" title="简单使用Docker"></a>简单使用Docker</h4><p>运行一个Docker容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run busybox echo &quot;Hello world&quot;</span><br></pre></td></tr></table></figure><p>这条命令背后是<br>1 Docker检查本地是否存在busybox镜像<br>2 Docker从registry拉取busybox镜像<br>3 Docker在一个被隔离的容器里面运行’’’ echo “Hello world” ‘’’</p><p>但是镜像一般是和想要运行的命令一起打包的，因此一般只要run一个打包进命令的image就可以了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run &lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure><p>例如，如果有一个node.js编写的http server源文件app.js，想要这个http server在容器中运行。可以提供像这样的一个Dockerfile。这个Dockerfile应该和app.js在一个文件夹下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM node:7 &#x2F;&#x2F; base image</span><br><span class="line">ADD app.js &#x2F;app.js &#x2F;&#x2F;表示将当前目录的app.js加入镜像的根目录下</span><br><span class="line">ENTRYPOINT [&quot;node&quot;, &quot;app.js&quot;] &#x2F;&#x2F;运行镜像时应该执行的命令</span><br></pre></td></tr></table></figure><p>运行下面的命令制作一个镜像。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t kubia .</span><br></pre></td></tr></table></figure><p>.表示基于当前目录制作image。在这个制作镜像的过程中，Docker将当前这个目录上传到Docker Daemon，Docker Daemon如果本地没有base image就去拉取，然后制作出新镜像。因此不要往文件夹里面放无用的文件。  </p><p>镜像不是一个大的二进制blob，而是由多层组成的。每个Dockerfile中的command都会在base image上再加一层。例如上面的Dockerfile中的ADD会给node:7增加一个layer，CMD会给它再增加一个layer。  </p><p>除了依靠Dockerfile，也可以手动制作镜像：拉起一个image，进去容器运行命令，退出后提交image即可。事实上Dockerfile也是这么做的，但是使用Dockerfile可以让以后制作同样镜像的行为自动化。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name kubia-container -p 8080:8080 -d kubia</span><br></pre></td></tr></table></figure><p>这个命令让Docker运行一个名为kubia-container的容器，镜像为kubia。-d表示这个容器会与控制台分离(detached)，即在后台运行。宿主机的8080端口会映射到容器的8080端口。对于win和mac，docker的宿主机是运行Docker Daemon的VM，可以通过DOCKER_HOST环境变量查看它的IP地址。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker ps &#x2F;&#x2F; list running containers</span><br><span class="line">docker inspect container_name &#x2F;&#x2F;输出一个json文档对容器进行详细描述</span><br><span class="line">docker exec -it container_name bash &#x2F;&#x2F; -i表示打开STDIN，-t表示分配一个伪终端(TTY)</span><br><span class="line">docker stop container-name &#x2F;&#x2F;仅仅是stop的，可以通过docker ps -a看到</span><br><span class="line">docker rm container-name &#x2F;&#x2F;彻底移除这个容器</span><br></pre></td></tr></table></figure><p>容器中的pid使用的是自己的namespace，因此要运行的命令的pid为1。在宿主机上也能看到容器中运行的进程，但其pid必然不是1。</p><h5 id="把image推到image-registry上"><a href="#把image推到image-registry上" class="headerlink" title="把image推到image registry上"></a>把image推到image registry上</h5><p>按照Docker Hub要求，image的tag应该由Docker Hub ID开头，可以通过<code>docker tag kubia luksa/kubia</code>给这个image增加一个tag，这里并不是将image重命名了。通过<code>docker images</code>可以看到现在是同一个image拥有两个tag。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker push luska&#x2F;kubia</span><br><span class="line">docker run -p 8080:8080 -d luksa&#x2F;kubia &#x2F;&#x2F;如果本地没有则从Docker Registry拉取镜像</span><br></pre></td></tr></table></figure><h4 id="简单使用K8s"><a href="#简单使用K8s" class="headerlink" title="简单使用K8s"></a>简单使用K8s</h4><p>首先应该有一个K8s集群，可以通过Minikube或者GKE等创建。<br>如图，用户通过kubectl与K8s集群交互。<br><img src="k8s_fig2.png" alt="用户与K8s集群交互"></p><h5 id="通过K8s部署应用"><a href="#通过K8s部署应用" class="headerlink" title="通过K8s部署应用"></a>通过K8s部署应用</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl run kubia --image&#x3D;luska&#x2F;kubia --port&#x3D;8080 --generator&#x3D;run&#x2F;v1</span><br></pre></td></tr></table></figure><p>这条命令创建了一个名为kubia的replication controller，K8s中不直接创建pod，而是用过创建replication set或者deployment来创建pod。选项<code>--genertator=run/v1</code>表示这里创建的是一个replication controller而不是deployment。<code>--port=8080</code>表示这个应用监听8080端口。</p><p>Pod是若干相关联的容器组成的组，因此一个pod中可以有多个容器。每个容器运行一个进程，这些进程就像运行在一台物理机上一样。Pod是K8s的基础构建模块，但K8s一般不直接创建pod。</p><p>在上面这个命令中发生了以下几步<br>1 kubectl发出一个RESTful call给API Server<br>2 master node创建一个pod并将其调度到一个worker node上<br>3 被调度的worker node的kubelet看到pod被调度来，驱使Docker去拉镜像<br>4 Docker运行image，创建容器</p><p>但刚刚部署的服务仅能通过pod的cluster ip访问到，但是pod是短命的，因此这个服务的ip随时可能变动。因此通过service为这个应用暴露一个持久稳定的ip地址。因为svc分配到的ip在它的整个生命周期都不会变。或者说，因为svc生命周期长，所以它的ip很稳定。svc代表的是运行同一类服务的1个or多个pods的一个静态地址。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose rc kubia --type&#x3D;LoadBalancer --name kubia-http</span><br></pre></td></tr></table></figure><p>命令<code>kubectl expose</code>暴露了一个名为kubia-http的服务(service)，通过<code>kubectl get svc</code>可以看到这个svc的external ip，现在就可以通过这个external ip访问pod上的服务了。</p><p>在上面的例子中，<code>kubectl run</code>创建了一个replication controller，这个rc维护数量为1的pod。为了让这个pod能被K8s外界访问到，命令K8s将所有由这个rc管理的pod暴露为一个服务。<br><img src="" alt="一个rc，一个pod和一个svc"></p><p>Replication Controller可以通过命令快速水平扩容/缩容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale rc kubia --relicas&#x3D;3</span><br></pre></td></tr></table></figure><h3 id="Chapter-3-Pod"><a href="#Chapter-3-Pod" class="headerlink" title="Chapter 3 Pod"></a>Chapter 3 Pod</h3><p>Pod是K8s的中心概念，K8s的其他资源不是管理，暴露Pod，就是被Pod使用。<br>Pod是一组容器，但大多数情况下pod里只有一个容器。如果pod中含有多个容器，则它们一定运行在同一个worker node上。<br>多个运行单进程的<strong>容器</strong>优于运行多进程的单容器，因为容器没有管理进程的功能，如果诸多进程中的一个挂了，容器不能自行把它拉起来。另外多个进程在一个容器里会共用很多资源。例如stdout，这些进程的log会都挤在一起，无法分辨。<br>容器设计之时就是为了运行单进程的，除非是一个进程自己引发的子进程的情况。因为必须保证单个容器单个进程，但由存在需要多个进程协同工作的情况。因此pod通过囊括多个容器来填补这个空白。<br>K8s通过令一个pod上的所有容器使用相同的Linux namespace来模拟多个容器运行在一台物理机的情况。但是每个容器拥有其各自的文件系统，可以通过K8s的Volume令其共享一套文件系统。另外因为一个pod的多个容器相当于运行在一台物理机上，因此它们应该注意端口冲突的问题。<br>Pods间的网络是平的，即它们可以通过ip地址直接找到对方，不需要通过NAT。无论是同一worker node上的pods还是不同worker nodes上的pods都是如此。</p><p>Pod是K8s扩展的最小单位，而不是容器。因此应该把不同的进程放在不同的pod中，这样扩展比较方便。比如无状态的web server和后端数据库就应该分开，这样web server扩容时，数据库不应该随之增减实例。<br>但是如果是一个主要进程和若干个负责辅助其工作的进程，那么就可以放在一个pod中。  </p><p>总之，牢记尽量避免把多个进程放在一个容器，以及把多个容器放在一个pod就可以了。</p><h5 id="通过YAML或JSON来创建pod"><a href="#通过YAML或JSON来创建pod" class="headerlink" title="通过YAML或JSON来创建pod"></a>通过YAML或JSON来创建pod</h5><p><a href="http://kubernetes.io/docs/reference/">K8s API doc</a></p><p>通过<code>kubectl get po pod-name -o yaml</code>可以看到这个pod完整的yaml definition。一个yaml definition的主要内容包括<br>1 本yaml文件使用的K8s API version以及本yaml文件描述的资源类型<br>2 Metadata: 关于这个pod的信息，如name，namespace，label等<br>3 Spec: pod实际内容的描述，比如这个pod有什么容器，volume等<br>4 Status: 包含正在运行的pod的状态, 比如它现在运行正常吗，它的内部ip等其他基础信息</p><p>Pod的yaml definition内容很丰富，在用yaml创建pod的时候不用提供4。下面是一个创建pod的yaml的样例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-manual </span><br><span class="line">spec:</span><br><span class="line">  containers: &#x2F;&#x2F;这个pod包含1个容器</span><br><span class="line">  - image: luksa&#x2F;kubia</span><br><span class="line">    name: kubia &#x2F;&#x2F;给这个容器一个名字</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 8080</span><br><span class="line">      protocol: TCP</span><br></pre></td></tr></table></figure><p>在yaml文件中指明prot与否对于能不能通过这个端口个连上容器里面的服务没有影响，只不过可以让看yaml的人看得更明白。</p><p>在撰写manifest的时候，除了可以参考K8s API的文档，还可以利用<code>kubectl explain</code>命令查看各字段的含义。例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl explain pods</span><br><span class="line">kubectl explain pod.spec</span><br></pre></td></tr></table></figure><p>若想通过yaml文件创建pod，运行<code>kubectl create -f kubia-manual.yaml</code>即可。</p><p>在部署应用后希望查询应用的日志，调用<code>kubectl logs pod_name</code>或者登陆到worker node运行<code>docker logs &lt;container_id&gt;</code>。容器中的进程一般把日志直接写到stderr和stdout，而不是日志文件中。因为这样对于K8s和Docker可以直接获得日志。日志每天以及每10MBrotate一次，<code>kubectl logs</code>展示的是从上一次rotate到现在的日志。<br>如果一个pod里面有多个容器，那么查询日志时应该指定容器名，即<code>kubectl logs &lt;pod_name&gt; -c &lt;container_name&gt;</code><br>K8s只能查到还存在的容器的日志，如果想要保留被删除的容器的日志，需要一个cluster维度的日志中心(Ch17)。  </p><p>虽然pod创建成功，但是其中的服务还是无法访问。除了之前说的service，端口转发(port forwarding)也可以让用户可以访问到pod中的服务。端口转发是让用户通过本地的端口访问服务，service是给pod暴露了一个持久稳定的ip，无需端口，仅用ip即可。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl port-forward kubia-manual 8888:8080</span><br></pre></td></tr></table></figure><p>运行了该命令后，kubectl会拦截本地8888端口的请求，转发到kubia-manual这个pod的8080端口。</p><h5 id="用label管理pods"><a href="#用label管理pods" class="headerlink" title="用label管理pods"></a>用label管理pods</h5><p>Label是用户给K8s资源打上的任意键值对。一般会在创建资源的时候指定label，但是之后也可以热增加or热修改label。<br>Label可以在些yaml文件的时候就写好。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">metadata:</span><br><span class="line">  name: kubia-manual-v2</span><br><span class="line">  labels:</span><br><span class="line">    creation_method: manual</span><br><span class="line">    env: prod</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>运行下面命令查看label。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl creata -f kubia-manual-v2</span><br><span class="line">kubectl get po --show-labels </span><br><span class="line">kubectl get po -L creation_method,env \\ -L选项指定labels</span><br></pre></td></tr></table></figure><p>修改或增加label的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label po kubia-manual-v2 env&#x3D;debug --overwrite &#x2F;&#x2F;必须带--overwrite选项才能修改已有label</span><br></pre></td></tr></table></figure><h6 id="label-selector"><a href="#label-selector" class="headerlink" title="label selector"></a>label selector</h6><p>使用<code>-l</code>选项加上条件可以通过label筛选资源。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get po -l creation_method&#x3D;manual &#x2F; env &#x2F; &#39;!env&#39; &#x2F; !&#x3D; &#x2F; in (a, b) &#x2F; notin (a,b) ...</span><br></pre></td></tr></table></figure><p>同样也可以通过label管理worker node。  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node &lt;node_name&gt; gpu&#x3D;true</span><br></pre></td></tr></table></figure><p>使用<code>nodeSelector</code>可以把pod指定调度到符合某个label selector的worker nodes上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spec:</span><br><span class="line">  nodeSelector:</span><br><span class="line">    gpu: &quot;true&quot; &#x2F;&#x2F;这个pod只会被调度到包含gpu&#x3D;true的node</span><br><span class="line">  containers:</span><br></pre></td></tr></table></figure><p>每个node都有一个名为kubernetes.io/hostname的label，这个label的值是node是主机名。但是没有必要不要使用这个label来调度pod，因为这样使pod对单个node依赖。</p><h6 id="注解pod"><a href="#注解pod" class="headerlink" title="注解pod"></a>注解pod</h6><p>Annotating与label的区别在于<br>1 它的值可以很长，因为它是用来说明注解pod的键值对<br>2 它对于调度无影响<br>Annotations经常也被用于引入新feature。新的feature在beta阶段往往在annotation中出现。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl annotate pod &lt;pod_name&gt; &lt;key&gt;&#x3D;&lt;value&gt;</span><br></pre></td></tr></table></figure><h5 id="使用命名空间对资源进行分组"><a href="#使用命名空间对资源进行分组" class="headerlink" title="使用命名空间对资源进行分组"></a>使用命名空间对资源进行分组</h5><p>Namespace的作用是把资源分组，资源的名称只需在命名空间内唯一即可。但是cluster级别的资源不受namespace控制，比如node。除了资源隔离外，namespace还可以用来做访问控制和资源管理。</p><p>可以用yaml文件创建namespace，也可以用命令。用命令比简单。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace custom-namespace</span><br></pre></td></tr></table></figure><p>切换namespace</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-context $(kubectl config current-context) --namespace &lt;namespace_name&gt;</span><br></pre></td></tr></table></figure><p>Namespace提供的隔离不是低级别的，即不同的ns的pod是可以互相看见对方的。ns的网络隔离依赖与K8s的网络策略，如果K8s没有做ns间的网络隔离，那么就没有隔离。</p><h5 id="停止和移除pod"><a href="#停止和移除pod" class="headerlink" title="停止和移除pod"></a>停止和移除pod</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete po &lt;pod_name&gt;</span><br><span class="line">kubectl delete po -l &lt;label selector&gt;</span><br></pre></td></tr></table></figure><p>删除pod，K8s会终止这个pod的所有容器，K8s会向进程发送SIGTERM信号并等待一段时间。如果进程没有关掉，会再发送SIGKILL。因此应该保证容器中的进程可以处理SIGTERM信号。</p><p>也可以通过删除整个namespace来删除pod，删除ns可以删除ns上的所有pod。或者用<code>--all</code>选项。<br>如果使用来<code>kubeclt delete all --all</code>来删除所有资源，第一个all就是表示所有资源。但是仍然会有一些资源不会被这个命令删除，需要显式删除，比如Secret。K8s service也会被这个命令删除，但是会再重新拉起来一个。</p><h4 id="Chapter-4-Replication-and-other-controllers"><a href="#Chapter-4-Replication-and-other-controllers" class="headerlink" title="Chapter 4 Replication and other controllers"></a>Chapter 4 Replication and other controllers</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2021/03/05/hello-world/"/>
      <url>2021/03/05/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
